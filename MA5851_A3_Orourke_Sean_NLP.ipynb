{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect each page and if appropriate return details + sentiment\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime, timezone\n",
    "from functions import check_if_asx\n",
    "from functions import named_entities\n",
    "from functions import get_sentiment\n",
    "\n",
    "asxCompanies = pd.read_csv('ASX_Listed_Companies.csv')\n",
    "asxCompanies.drop('Listing date', axis = 1)\n",
    "\n",
    "sentimentByCompany_new = pd.DataFrame(columns=[\"date\", \"title\", \"asxTag\", \"sentiment\", \"articleLength\", \"namedInTitle\", 'author'])\n",
    "matches = []\n",
    "corpus = []\n",
    "\n",
    "rawCorpus = pd.read_csv('scrape2_raw.csv')\n",
    "\n",
    "for title in rawCorpus['title'].unique():\n",
    "\n",
    "    print(\"Checking : \" +str(title))\n",
    "    try:\n",
    "        article = rawCorpus[rawCorpus['title'] == title]\n",
    "        author = article['author']\n",
    "        time = article['date']\n",
    "        paragraphs = article['paragraph']\n",
    "\n",
    "\n",
    "        hasNe, toCheck, matchingCorpus = named_entities(title)\n",
    "        if hasNe:\n",
    "            hasAsx, asxTag, companyName, matchedEntity = check_if_asx(toCheck, asxCompanies)\n",
    "\n",
    "            # If listed on ASX assign all paragraphs sentiment to company unless paragraph mentions another ASX company\n",
    "            if hasAsx:\n",
    "                print(\"found in title - Entity : \" + str(matchedEntity) + \" Matched to : \" + str(asxTag) + \" , \" + str(companyName))\n",
    "                paraCount = 0\n",
    "                for paragraph in paragraphs:\n",
    "                    paraCount += 1\n",
    "\n",
    "                    # Check if paragraph has named entities and ASX Tag\n",
    "                    hasNe, toCheck, matchingCorpus = named_entities(paragraph)\n",
    "                    corpus.append(matchingCorpus)\n",
    "                    hasAsx_para = False\n",
    "                    if hasNe:\n",
    "                        hasAsx_para, asxTag_para, companyName_para, matchedEntity_para = check_if_asx(toCheck, asxCompanies)\n",
    "\n",
    "                    # If ASX Company found and differes from title Company return sentiment asociated with company found in paragraph\n",
    "                    if hasAsx_para and asxTag_para != asxTag:\n",
    "                        sentiment = get_sentiment(paragraph)\n",
    "                        new_row = pd.DataFrame(\n",
    "                            {\"date\": [time], \"title\": [title], \"asxTag\": [asxTag_para], \"sentiment\": [sentiment],\n",
    "                             \"articleLength\": [len(paragraphs)], \"namedInTitle\": False, \"authour\": [author]})\n",
    "                        sentimentByCompany_new = sentimentByCompany_new.append(new_row, ignore_index=True)\n",
    "                        print(\"1 - Found in paragraph, overriding title - Entity : \" + str(\n",
    "                            matchedEntity_para) + \" Matched to : \" + str(asxTag_para) + \" , \" + str(companyName)\n",
    "                              + \" getting sentiment for : \" + str(paraCount) + \" of \" + str(len(paragraphs)))\n",
    "                        matches.append((matchedEntity_para, asxTag_para))\n",
    "\n",
    "                    # otherwise return sentiment from paragraph assigned to company from title\n",
    "                    else:\n",
    "                        sentiment = get_sentiment(paragraph)\n",
    "                        new_row = pd.DataFrame(\n",
    "                            {\"date\": [time], \"title\": [title], \"asxTag\": [asxTag], \"sentiment\": [sentiment],\n",
    "                             \"articleLength\": [len(paragraphs)], \"namedInTitle\": True, \"authour\": [author]})\n",
    "                        sentimentByCompany_new = sentimentByCompany_new.append(new_row, ignore_index=True)\n",
    "                        print(\"2 - From para : \" + str(matchedEntity) + \" Matched to : \" + str(\n",
    "                            asxTag) + \" getting sentiment for : \" + str(paraCount) + \" of \" + str(len(paragraphs)))\n",
    "                        matches.append((matchedEntity, asxTag))\n",
    "\n",
    "        # If no named entity in title check each paragraph\n",
    "        elif not hasNe:\n",
    "\n",
    "            # Iterate over all Paragraphs\n",
    "            paraCount = 0\n",
    "            for paragraph in paragraphs:\n",
    "                paraCount += 1\n",
    "\n",
    "\n",
    "                # Check if any named entities in paragraph\n",
    "                hasNe, toCheck, matchingCorpus = named_entities(paragraph)\n",
    "                corpus.append(matchingCorpus)\n",
    "                if hasNe:\n",
    "\n",
    "                    # If named entity present check if it is listed on ASX\n",
    "                    hasAsx, asxTag, companyName, matchedEntity = check_if_asx(toCheck,asxCompanies)\n",
    "                    # If ASX found find sentiment and return\n",
    "                    if hasAsx:\n",
    "                        sentiment = get_sentiment(paragraph)\n",
    "                        new_row = pd.DataFrame(\n",
    "                            {\"date\": [time], \"title\": [title], \"asxTag\": [asxTag], \"sentiment\": [sentiment],\n",
    "                             \"articleLength\": [len(paragraphs)], \"namedInTitle\": False, \"authour\": [author]})\n",
    "                        sentimentByCompany_new = sentimentByCompany_new.append(new_row, ignore_index=True)\n",
    "                        print(\"4 - found in paragraph - Entity : \" + str(matchedEntity) + \" Matched to : \" + str(\n",
    "                            asxTag) + \" getting sentiment for : \" + str(paraCount) + \" of \" + str(len(paragraphs)))\n",
    "                        matches.append((matchedEntity, asxTag))\n",
    "\n",
    "                else:\n",
    "                    print(\"Has no named entities : \" + str(title) + \" \" + str(paraCount) + \" of \" + str(len(paragraphs)))\n",
    "                    \n",
    "    except:\n",
    "        print(\"error with : \" + str(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentByCompany_new.to_csv('scrape2_sentiment.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportMatches = pd.DataFrame({\"matches\":matches})\n",
    "exportMatches.to_csv('matches_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataTurks. (2018). Stanford CoreNLP: Training your own custom NER tagger. <br>\n",
    "Retrieved from \n",
    "https://medium.com/swlh/stanford-corenlp-training-your-own-custom-ner-tagger-8119cc7dfc06 <br>\n",
    "Gitau, C. (2018). Fuzzy String Matching. <br>\n",
    "Retrieved from https://towardsdatascience.com/fuzzy-string-matching-in-python-68f240d910fe<br>\n",
    "Godbole, N., Srinivasaiah, M., & Skiena, s. Large-Scale Sentiment Analysis for News and Blogs. \n",
    "Kaewphan, S., Hakala, K., Miekka, N., Salakoski, T., & Ginter, F. (2018). Wide-scope biomedical named entity recognition and normalization with CREs fuzzy matching and character level modeling. Database. doi:10.1093<br>\n",
    "Magajna, T. Text Classification with State of the Art NLP Library â€” Flair.<br> Retrieved from https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
